#!/bin/bash

# Udyam Scraping Quick Start Script
# This script automates the entire scraping process

echo "ğŸš€ Udyam Registration Portal Scraping - Quick Start"
echo "=================================================="

# Check if Node.js is installed
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js is not installed. Please install Node.js 18+ first."
    exit 1
fi

# Check if npm is installed
if ! command -v npm &> /dev/null; then
    echo "âŒ npm is not installed. Please install npm first."
    exit 1
fi

echo "âœ… Node.js and npm found"

# Install dependencies
echo "ğŸ“¦ Installing dependencies..."
npm install

if [ $? -ne 0 ]; then
    echo "âŒ Failed to install dependencies"
    exit 1
fi

echo "âœ… Dependencies installed successfully"

# Run the scraper
echo "ğŸ•·ï¸  Starting web scraping..."
echo "âš ï¸  Note: This will open a browser window. Please don't close it until scraping is complete."
echo ""

npm run scrape:all

if [ $? -ne 0 ]; then
    echo "âŒ Scraping failed"
    exit 1
fi

echo "âœ… Scraping completed successfully"

# Validate the scraped data
echo "ğŸ” Validating scraped data..."
npm run validate

if [ $? -ne 0 ]; then
    echo "âš ï¸  Validation found issues. Please review the scraped data."
else
    echo "âœ… Data validation passed"
fi

# Generate schemas and components
echo "ğŸ”§ Generating schemas and React components..."
npm run generate-schema

if [ $? -ne 0 ]; then
    echo "âŒ Schema generation failed"
    exit 1
fi

echo "âœ… Schema generation completed"

echo ""
echo "ğŸ‰ All done! Here's what was created:"
echo "ğŸ“ Scraped data files in ./scraping/"
echo "ğŸ“ Generated schemas in ./src/schemas/"
echo ""
echo "Next steps:"
echo "1. Review the generated schemas and components"
echo "2. Integrate them into your main application"
echo "3. Test the forms with real data"
echo "4. Customize styling and validation as needed"
